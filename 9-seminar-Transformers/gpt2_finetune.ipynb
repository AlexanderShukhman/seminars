{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created by: c00k1ez (https://github.com/c00k1ez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import transformers\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
    "\n",
    "from src.utils import get_answer\n",
    "from src.gpt2.data_parser import Dialogue, DataParser\n",
    "from src.gpt2.dataset import DialogueDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_config = {\n",
    "    'pad_len': 100,\n",
    "    'train_batch_size': 10,\n",
    "    'model_name': 'gpt2',\n",
    "    'lr': 5e-5,\n",
    "    'residual_dropout': 0.7,\n",
    "    'embedding_dropout': 0.7,\n",
    "    'attention_dropout': 0.7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading: 100%|██████████| 548M/548M [06:21<00:00, 1.44MB/s]\n"
    }
   ],
   "source": [
    "config = GPT2Config.from_pretrained(params_config['model_name'])\n",
    "config.resid_pdrop = params_config['residual_dropout']\n",
    "config.attn_pdrop = params_config['attention_dropout']\n",
    "config.embd_pdrop = params_config['embedding_dropout']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(params_config['model_name'], config=config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Embedding(50259, 768)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(params_config['model_name'])\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': ['[CONTEXT]', '[ANSWER]']})\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = DataParser('./data/TwitterLowerAsciiCorpus.txt')\n",
    "train, test = parser.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Our dataset contains 8574 context-answer pairs and unique 1983 dialogues\nThere are 10046 unique tokens in dataset and 233751 tokens at all. Notice, that small GPT2 have vocabulary with 50k sub-words.\n\nMost common 10 tokens:\n. : 7196\nĠi : 7186\nĠthe : 4561\nĠto : 4025\nĠyou : 3977\n, : 3602\nĠa : 3373\nĠit : 3218\nĠand : 2602\n's : 2285\n"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('Our dataset contains {} context-answer pairs and unique {} dialogues'.format(len(parser.all_pairs), len(parser.dialogues)))\n",
    "\n",
    "tokens = []\n",
    "for sample in parser.all_pairs:\n",
    "    sample = tokenizer.tokenize(sample['context'] + ' ' + sample['answer'])\n",
    "    tokens.extend(sample)\n",
    "counter = Counter(tokens)\n",
    "print('There are {} unique tokens in dataset and {} tokens at all. Notice, that small GPT2 have vocabulary with 50k sub-words.'.format(len(counter), sum([v for _,v in dict(counter).items()])))\n",
    "print('')\n",
    "print('Most common 10 tokens:')\n",
    "for token, freq in counter.most_common(10):\n",
    "    print('{} : {}'.format(token, freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DialogueDataset(train, tokenizer, params_config['pad_len'])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, params_config['train_batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = transformers.AdamW(model.parameters(), lr=params_config['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, epoch_num, device, log_interval=100):\n",
    "    losses = []\n",
    "    avg_loss = []\n",
    "    step = 1\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, mask, label = batch['sample'], batch['mask'], batch['label']\n",
    "        input_ids = input_ids.to(device)\n",
    "        mask = mask.to(device)\n",
    "        label = label.to(device)\n",
    "        outputs = model(input_ids, attention_mask=mask, labels=label)\n",
    "        loss, logits = outputs[:2]\n",
    "        avg_loss.append(loss.detach().item())\n",
    "        if step % log_interval == 0:\n",
    "            val_loss = sum(avg_loss) / len(avg_loss)\n",
    "            losses.append(val_loss)\n",
    "            avg_loss = []\n",
    "            print('epoch {}\\t[{}/{}]\\tloss = {:.4f}'.format(epoch_num, step, len(loader), val_loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    ep_losses = train_epoch(model, train_loader, optimizer, epoch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(torch.device('cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answer(\"where are you?\", model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitpytorchenvcondadd1df8879e6648999b744b4f723a1baa",
   "display_name": "Python 3.7.6 64-bit ('pytorch_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}