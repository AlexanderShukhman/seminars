{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by: c00k1ez (https://github.com/c00k1ez)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora question pairs classification with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Paraphrase detection is challenging NLP problem of detecting whether multiple phrases have the same meaning. \n",
    " In this notebook, we are going to build a baseline solution for an unusual classification task. \n",
    "\n",
    " For token embeddings we are going to use BERT model. Read more [here](http://jalammar.github.io/illustrated-bert/) and [here](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.bert.models import BertClassifier\n",
    "from src.bert.dataset import PairsDataset\n",
    "from src.bert.data_parser import DataParser\n",
    "from src.utils import seed_all\n",
    "\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_name': 'distilbert-base-uncased',\n",
    "    'pad_len': 256,\n",
    "    'batch_size': 30,\n",
    "    'lr': 5e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to use BERT without enough computation resources is a distilled version of this model - DistilBert by HuggingFace. \n",
    "[Blogpost](https://medium.com/huggingface/distilbert-8cf3380435b5) about DistilBert and [distillation](https://blog.floydhub.com/knowledge-distillation/).\n",
    "\n",
    "Models, that you can use too:\n",
    "* `BertModel`\n",
    "* `TransfoXLModel`\n",
    "* `XLNetModel`\n",
    "* `ElectraModel`\n",
    "* `RobertaModel`\n",
    "* `XLMRobertaModel`\n",
    "* `AlbertModel`  \n",
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 438kB/s]\nDownloading: 100%|██████████| 442/442 [00:00<00:00, 109kB/s]\nDownloading: 100%|██████████| 268M/268M [04:22<00:00, 1.02MB/s]\n"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(config['model_name'])\n",
    "bert_model = DistilBertModel.from_pretrained(config['model_name'])\n",
    "\n",
    "for p in bert_model.parameters():\n",
    "    p.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = DataParser('./data/questions.csv')\n",
    "train, test = parser.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Our dataset contains 404351 question pairs.\nThere are 25855 unique tokens in dataset and 11083222 tokens at all.\n\nMost common 10 tokens:\n? : 852527\nthe : 378272\nwhat : 327913\nis : 270823\ni : 224246\nhow : 220984\na : 212801\nto : 206127\nin : 201179\ndo : 161465\n"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('Our dataset contains {} question pairs.'.format(len(train)))\n",
    "\n",
    "tokens = []\n",
    "for sample in parser.question_pairs:\n",
    "    sample = tokenizer.tokenize(sample[0] + ' ' + sample[1])\n",
    "    tokens.extend(sample)\n",
    "counter = Counter(tokens)\n",
    "print('There are {} unique tokens in dataset and {} tokens at all.'.format(len(counter), sum([v for _,v in dict(counter).items()])))\n",
    "print('')\n",
    "print('Most common 10 tokens:')\n",
    "for token, freq in counter.most_common(10):\n",
    "    print('{} : {}'.format(token, freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairsDataset(train, tokenizer, config['pad_len'])\n",
    "#test_dataset = PairsDataset(test, tokenizer, config['pad_len'])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, config['batch_size'], shuffle=True)\n",
    "#test_loader = torch.utils.data.DataLoader(test_dataset, config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = BertClassifier(bert_model).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, you have to implement `DataParser.train_test_split` and `validation` methods to validate with the macro F1 score.\n",
    "## How to improve this model results?\n",
    "* Play with other models instead of DistilBert: classic BERT, ALBERT, RoBERTa, TinyBERT, etc.\n",
    "* Implement correct MeanPooling/MaxPooling layer (notice that you have `[PAD]` tokens during training and you have to \"exclude\" them from mean or max value computing).\n",
    "* Use more complex model after BERT embeddings.\n",
    "* You can try to use the siamese network to encode the first and second questions independently with metric learning. Read more about it [here](https://parajain.github.io/metric_learning_tutorial/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def validation(model, test_loader, device):\n",
    "    model.eval()\n",
    "    avg_val_loss = []\n",
    "    avg_val_loss_value = -1.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    ################### INSERT YOUR CODE HERE ###################\n",
    "        \n",
    "    ################### INSERT YOUR CODE HERE ###################\n",
    "    model.train()\n",
    "    return avg_val_loss_value, f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, test_loader, optimizer, epoch_num, device, criterion, log_interval=200):\n",
    "    losses = []\n",
    "    avg_loss = []\n",
    "    step = 1\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        for key in batch.keys():\n",
    "            batch[key] = batch[key].to(device)\n",
    "        label = batch['label'].view(-1)\n",
    "        logits = model(batch)\n",
    "        loss = criterion(logits, label)\n",
    "        avg_loss.append(loss.detach().item())\n",
    "        if step % log_interval == 0:\n",
    "            val_loss = sum(avg_loss) / len(avg_loss)\n",
    "            losses.append(val_loss)\n",
    "            avg_loss = []\n",
    "            print('epoch {}\\t[{}/{}]\\ttrain_loss = {:.4f}'.format(epoch_num, step, len(train_loader)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = train_epoch(model, train_loader, None, optimizer, epoch, device, criterion)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitpytorchenvcondadd1df8879e6648999b744b4f723a1baa",
   "display_name": "Python 3.7.6 64-bit ('pytorch_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}